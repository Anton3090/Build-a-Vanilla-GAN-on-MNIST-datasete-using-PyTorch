{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7ef26f7",
   "metadata": {},
   "source": [
    "# Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0b316dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed5039ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if CUDA (GPU) is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc6beb1",
   "metadata": {},
   "source": [
    "# Generator Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae962ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Generator model\n",
    "# The Generator model transforms random noise into realistic images using a series of layers and activation functions.\n",
    "class Generator(nn.Module):\n",
    "   \n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "       # Fully connected layers to generate an image from random noise\n",
    "        self.fc1 = nn.Linear(100,256)  # First layer (100 -> 256)\n",
    "        self.fc2 = nn.Linear(256,512)  # Second layer (256 -> 512)\n",
    "        self.fc3 = nn.Linear(512,1024) # Third layer (512 -> 1024)\n",
    "        self.fc4 = nn.Linear(1024,28 * 28)  # Output layer (1024 -> 28x28)\n",
    "        \n",
    "        # Activation functions\n",
    "        self.relu = nn.ReLU()\n",
    "        self.tanh = nn.Tanh()  # Used to scale the output to [-1, 1]\n",
    "\n",
    "    \n",
    "   \n",
    "    def forward(self, z):\n",
    "       \n",
    "        # Apply layers and activation functions sequentially\n",
    "        x = self.relu(self.fc1(z))  # First hidden layer\n",
    "        x = self.relu(self.fc2(x))  # Second hidden layer\n",
    "        x = self.relu(self.fc3(x))  # Third hidden layer\n",
    "        x = self.tanh(self.fc4(x))  # Output layer with Tanh activation\n",
    "       \n",
    "        return x.view(-1,1,28,28)  # Reshape the output to image size (1, 28, 28)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748e3a8a",
   "metadata": {},
   "source": [
    "# Discriminator Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a1d4c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Discriminator model\n",
    "# The Discriminator model classifies images as real or fake. \n",
    "# It takes an image as input, passes it through a series of layers and activation functions, and outputs a probability of the image being real.\n",
    "class Discriminator(nn.Module):\n",
    "   \n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        # Fully connected layers to classify if an image is real or fake\n",
    "        self.fc1 = nn.Linear(28 * 28, 1024)  # Input layer (28x28 -> 1024)\n",
    "        self.fc2 = nn.Linear(1024,512)  # Hidden layer (1024 -> 512)\n",
    "        self.fc3 = nn.Linear(512,256)  # Hidden layer (512 -> 256)\n",
    "        self.fc4 = nn.Linear(256,1)  # Output layer (256 -> 1)\n",
    "\n",
    "        # Activation functions\n",
    "        self.leaky_relu = nn.LeakyReLU(0.2)  # LeakyReLU used for negative slope\n",
    "        self.sigmoid = nn.Sigmoid()  # Sigmoid for binary classification (real or fake)\n",
    "\n",
    "    \n",
    "   \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = x.view(-1, 28 * 28)  # Flatten the input image to a 1D vector\n",
    "        x = self.leaky_relu(self.fc1(x))  # Apply first hidden layer\n",
    "        x = self.leaky_relu(self.fc2(x))  # Apply second hidden layer\n",
    "        x = self.leaky_relu(self.fc3(x))  # Apply third hidden layer\n",
    "        x = self.sigmoid(self.fc4(x))  # Output layer\n",
    "        \n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78a7da1",
   "metadata": {},
   "source": [
    "# Noise Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "979144c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random noise\n",
    "# This code generates random numbers to be used as input for the Generator model.\n",
    "def generate_noise(batch_size,z_dim = 100):\n",
    "    \n",
    "    return torch.randn(batch_size,z_dim,device = device)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98344557",
   "metadata": {},
   "source": [
    "# Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b016536a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gan(generator, discriminator, train_loader, optimizer_g, optimizer_d, criterion, epochs=20):\n",
    "   \n",
    "    for epoch in range(epochs):  # Loop through the number of epochs\n",
    "        \n",
    "        for i, (real_images, _) in enumerate(train_loader):  # Iterate over the dataset\n",
    "           \n",
    "            real_images =real_images.to(device)  # Move real images to device (GPU)\n",
    "            batch_size =real_images.size(0)  # Get the batch size\n",
    "            labels_real =torch.ones(batch_size,1,device=device)  # Labels for real images\n",
    "            labels_fake =torch.zeros(batch_size,1,device=device)  # Labels for fake images\n",
    "\n",
    "            \n",
    "            # Train the discriminator: Real images\n",
    "            optimizer_d.zero_grad()  # Zero the gradients of the discriminator\n",
    "            output_real =discriminator(real_images)  # Pass real images through the discriminator\n",
    "            d_loss_real =criterion(output_real , labels_real)  # Loss for real images\n",
    "            d_loss_real.backward()  # Backpropagate the loss\n",
    "            #This line backpropagates the calculated loss for real images through the discriminator's layers to update its weights.\n",
    "\n",
    "           \n",
    "            \n",
    "            # Generate fake images from the generator\n",
    "            noise = generate_noise( batch_size )  #Generate random noise\n",
    "            fake_images = generator( noise )  # Generate fake images from the noise\n",
    "            output_fake = discriminator( fake_images.detach() )  # Get discriminator's output on fake images (detached from graph)\n",
    "            d_loss_fake = criterion( output_fake, labels_fake )  # Loss for fake images\n",
    "            d_loss_fake.backward()  #Backpropagate the loss\n",
    "\n",
    "            \n",
    "            \n",
    "            optimizer_d.step()  # Update the discriminator's weights\n",
    "            d_loss= d_loss_real + d_loss_fake  # Total discriminator loss\n",
    "\n",
    "           \n",
    "            # Train the generator: Fake images\n",
    "            optimizer_g.zero_grad()  # Zero the gradients of the generator\n",
    "            output_fake_for_g =discriminator( fake_images )  # Get discriminator's output on fake images\n",
    "            g_loss = criterion(output_fake_for_g , labels_real)  # Generator loss (trying to fool the discriminator)\n",
    "            g_loss.backward()  # Backpropagate the loss\n",
    "            optimizer_g.step()  # Update the generator's weights\n",
    "\n",
    "            \n",
    "            # Print the progress\n",
    "            if i%100 == 0:\n",
    "                print(f\"Epoch [{epoch+1}/{epochs}], Step [{i+1}/{len(train_loader)}], \"\n",
    "                      f\"D Loss: {d_loss.item()}, G Loss: {g_loss.item()}\")\n",
    "\n",
    "        \n",
    "        # Save generated images after each epoch\n",
    "        if (epoch + 1) %5 == 0:\n",
    "            save_generated_images(generator, epoch)\n",
    "\n",
    "\n",
    "#Training the Discriminator: It feeds real images to the discriminator and calculates the loss. Then, it generates fake images and feeds them to the discriminator, calculating another loss. The discriminator's weights are updated to better distinguish real from fake.\n",
    "#Training the Generator: It generates fake images and feeds them to the discriminator. The goal is to trick the discriminator into thinking they are real. The generator's weights are updated to improve its ability to create realistic images.\n",
    "\n",
    "\n",
    "#  After every 100 steps, it prints the current epoch , step number , discriminator loss, and generator loss.\n",
    "#  Every 5 epochs , it saves a set of images generated by the current generator model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31706544",
   "metadata": {},
   "source": [
    "# Save Generated Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4477ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_generated_images(generator, epoch, num_images=16):\n",
    "    noise = generate_noise(num_images)  # Generate random noise\n",
    "    fake_images =  generator(noise)  #Generate fake images from the noise\n",
    "    fake_images = fake_images.cpu().detach().numpy()  # Move images to CPU and detach from graph\n",
    "    fake_images = fake_images * 0.5 + 0.5  # Rescale to [0, 1] from [-1, 1]\n",
    "    fake_images = np.transpose(fake_images, (0 , 2 , 3 , 1))  # Change the shape to (num_images, 28, 28, 1)\n",
    "\n",
    "    # Plot and save the generated images\n",
    "    fig, axes = plt.subplots(4,4,figsize=( 4 , 4 ))\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            axes[i,j].imshow(fake_images[i *  4 + j], cmap='gray')  # Show image\n",
    "            axes[i,j].axis('off')  # Hide axis\n",
    "    \n",
    "    plt.tight_layout()  # Adjust layout\n",
    "    plt.savefig(f\"generated_images_epoch_{epoch+1}.png\")  # Save image\n",
    "    plt.close()  # Close the plot\n",
    "    \n",
    "    \n",
    "   # This code saves generated images after each epoch by plotting them and saving the plot as an image ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53627f15",
   "metadata": {},
   "source": [
    "# Main Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8761dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [1/938], D Loss: 1.3938807249069214, G Loss: 0.6938387751579285\n",
      "Epoch [1/5], Step [101/938], D Loss: 0.9779897928237915, G Loss: 1.3167881965637207\n",
      "Epoch [1/5], Step [201/938], D Loss: 0.5127428770065308, G Loss: 1.7473915815353394\n",
      "Epoch [1/5], Step [301/938], D Loss: 0.3738122582435608, G Loss: 3.528465747833252\n",
      "Epoch [1/5], Step [401/938], D Loss: 0.2638869285583496, G Loss: 2.525359869003296\n",
      "Epoch [1/5], Step [501/938], D Loss: 1.6985667943954468, G Loss: 5.8629374504089355\n",
      "Epoch [1/5], Step [601/938], D Loss: 0.6152112483978271, G Loss: 4.264281749725342\n",
      "Epoch [1/5], Step [701/938], D Loss: 0.12252391874790192, G Loss: 3.8571293354034424\n",
      "Epoch [1/5], Step [801/938], D Loss: 0.23493826389312744, G Loss: 2.3631832599639893\n",
      "Epoch [1/5], Step [901/938], D Loss: 0.22982898354530334, G Loss: 5.735939979553223\n",
      "Epoch [2/5], Step [1/938], D Loss: 0.42187952995300293, G Loss: 2.026096820831299\n",
      "Epoch [2/5], Step [101/938], D Loss: 0.3406374752521515, G Loss: 4.854226112365723\n",
      "Epoch [2/5], Step [201/938], D Loss: 0.3615354597568512, G Loss: 1.6034209728240967\n",
      "Epoch [2/5], Step [301/938], D Loss: 0.35661911964416504, G Loss: 1.4747588634490967\n",
      "Epoch [2/5], Step [401/938], D Loss: 0.1492791771888733, G Loss: 5.091639518737793\n",
      "Epoch [2/5], Step [501/938], D Loss: 0.02573135867714882, G Loss: 7.55551290512085\n",
      "Epoch [2/5], Step [601/938], D Loss: 0.8190411329269409, G Loss: 5.0607523918151855\n",
      "Epoch [2/5], Step [701/938], D Loss: 0.7281164526939392, G Loss: 10.043758392333984\n",
      "Epoch [2/5], Step [801/938], D Loss: 0.10160476714372635, G Loss: 6.2492194175720215\n",
      "Epoch [2/5], Step [901/938], D Loss: 2.549091339111328, G Loss: 6.148922920227051\n",
      "Epoch [3/5], Step [1/938], D Loss: 0.22814592719078064, G Loss: 3.9949917793273926\n",
      "Epoch [3/5], Step [101/938], D Loss: 0.2976188063621521, G Loss: 5.5563249588012695\n",
      "Epoch [3/5], Step [201/938], D Loss: 0.06729692965745926, G Loss: 3.6812527179718018\n",
      "Epoch [3/5], Step [301/938], D Loss: 0.35323500633239746, G Loss: 2.643641948699951\n",
      "Epoch [3/5], Step [401/938], D Loss: 0.41379615664482117, G Loss: 6.9950456619262695\n",
      "Epoch [3/5], Step [501/938], D Loss: 0.2157941460609436, G Loss: 1.7949116230010986\n",
      "Epoch [3/5], Step [601/938], D Loss: 0.3334312438964844, G Loss: 2.7440178394317627\n",
      "Epoch [3/5], Step [701/938], D Loss: 0.3058381676673889, G Loss: 1.885395884513855\n",
      "Epoch [3/5], Step [801/938], D Loss: 0.22364985942840576, G Loss: 3.1843371391296387\n",
      "Epoch [3/5], Step [901/938], D Loss: 0.19438804686069489, G Loss: 2.891914129257202\n",
      "Epoch [4/5], Step [1/938], D Loss: 0.20092105865478516, G Loss: 3.7920260429382324\n",
      "Epoch [4/5], Step [101/938], D Loss: 0.18844303488731384, G Loss: 3.680682897567749\n",
      "Epoch [4/5], Step [201/938], D Loss: 0.10202349722385406, G Loss: 3.654413938522339\n",
      "Epoch [4/5], Step [301/938], D Loss: 0.22475281357765198, G Loss: 3.106433153152466\n",
      "Epoch [4/5], Step [401/938], D Loss: 0.24652063846588135, G Loss: 2.8449172973632812\n",
      "Epoch [4/5], Step [501/938], D Loss: 0.2858816385269165, G Loss: 2.8439455032348633\n",
      "Epoch [4/5], Step [601/938], D Loss: 0.2639431953430176, G Loss: 2.508774757385254\n",
      "Epoch [4/5], Step [701/938], D Loss: 1.1632887125015259, G Loss: 1.5131356716156006\n",
      "Epoch [4/5], Step [801/938], D Loss: 0.669597327709198, G Loss: 6.981938362121582\n",
      "Epoch [4/5], Step [901/938], D Loss: 0.19948682188987732, G Loss: 3.5168042182922363\n",
      "Epoch [5/5], Step [1/938], D Loss: 0.28384873270988464, G Loss: 2.8683297634124756\n",
      "Epoch [5/5], Step [101/938], D Loss: 0.3974599838256836, G Loss: 1.671146035194397\n",
      "Epoch [5/5], Step [201/938], D Loss: 0.407003790140152, G Loss: 2.392094135284424\n",
      "Epoch [5/5], Step [301/938], D Loss: 0.3843257427215576, G Loss: 2.6853160858154297\n",
      "Epoch [5/5], Step [401/938], D Loss: 0.273906946182251, G Loss: 2.548551321029663\n",
      "Epoch [5/5], Step [501/938], D Loss: 0.4872482419013977, G Loss: 2.3422927856445312\n",
      "Epoch [5/5], Step [601/938], D Loss: 0.22554855048656464, G Loss: 3.0095512866973877\n",
      "Epoch [5/5], Step [701/938], D Loss: 0.7225089073181152, G Loss: 3.5289182662963867\n",
      "Epoch [5/5], Step [801/938], D Loss: 0.2590551972389221, G Loss: 2.8258755207061768\n",
      "Epoch [5/5], Step [901/938], D Loss: 0.34050077199935913, G Loss: 2.281564235687256\n"
     ]
    }
   ],
   "source": [
    "# Initialize the models\n",
    "generator = Generator().to(device)  # Move generator to GPU if available\n",
    "discriminator = Discriminator().to(device)  # Move discriminator to GPU if available\n",
    "\n",
    "\n",
    "# Define loss function and optimizers\n",
    "criterion = nn.BCELoss()  # Binary Cross-Entropy loss function for classification\n",
    "optimizer_g = optim.Adam(generator.parameters() , lr=0.0002 , betas=(0.5,0.999))  # Adam optimizer for the generator\n",
    "optimizer_d = optim.Adam(discriminator.parameters() , lr=0.0002 , betas=(0.5,0.999))  # Adam optimizer for the discriminator\n",
    "#this is an optimizer that uses the Adam algorithm for efficient gradient-based optimization.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Load the MNIST dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor() ,  # Convert images to Tensor (This converts a PIL Image or a NumPy array to a PyTorch Tensor)\n",
    "    transforms.Normalize(mean=[0.5] , std=[0.5])  # Normalize to [-1, 1]\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('.', train=True ,download=True ,transform=transform),\n",
    "    batch_size=64 , shuffle=True \n",
    "    # Batch size and shuffle the dataset\n",
    "    #This will ensure that the data is randomly shuffled before each epoch, which is important for better training and generalization of the model.\n",
    "    # Batch size is the number of training examples  used in one iteration of training a machine learning model.\n",
    ")\n",
    "\n",
    "\n",
    "# Train the GAN on MNIST dataset\n",
    "train_gan(generator , discriminator , train_loader , optimizer_g , optimizer_d , criterion , epochs=5)\n",
    "\n",
    "\n",
    "# This code sets up and trains a GAN to generate images similar to the MNIST dataset .\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50cacfe5",
   "metadata": {},
   "source": [
    "# Conclusion :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b9ccf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This Vanilla GAN implementation in PyTorch is a straightforward way to start experimenting with GANs on the MNIST dataset.\n",
    "#You can improve the model by using more sophisticated architectures, adding advanced techniques like batch normalization or using a deeper neural network."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
